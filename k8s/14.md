Lab 14.

Components of the stack:

The Prometheus Operator in our case uses Kubernetes custom resources to deploy and manage other components, making it simpler. 

Prometheus centralizes and stores metrics and alerts. It stores data locally which allows it to work faster.

Alertmanager works with alerts which were sent by Prometheus server. It deduplicates and routs them to the correct receiver. Similar alerts are grouped into 1 notification. If certain alerts are firing, some others may be supressed. Alerts can be muted for a certain time.

Prometheus node-exporter collects different metrics, exposing stats for CPU frequncy, network driver stats and others. It supports many collectors for every OS.

Prometheus Adapter for Kubernetes Metrics APIs collects the names of available metrics from Prometheus, but shows only those who follow certain forms.

kube-state-metrics generates metrics from Kubernetes API. Because of it, we can see metrics specifically for Pods, Nodes, etc. But it may show different values from kubectl. They are served as plaintext in order to be consumed by Prometheus.

Grafana is for the visualisation of dashboards. We already worked with it before. Because of it, we can see the metrics clearly in a nice way.

Output of 'kubectl get po,sts,svc,pvc,cm'. We see different pods for some of the components described above, 2 different stateful sets, services for all components, persistent volume claim which didn't change after Lab 13, and MANY configmap objects for storing key-value pairs.
![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-37-02.jpg?raw=true)
![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-37-20.jpg?raw=true)

What we can see on Dashboard:

Stateful set consumes 0,0339GB, which is less than 1% of CPU.
![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-41-17.jpg?raw=true)

All your-app pods have exactly the same CPU usage, 0.09. But prometheus-monitoring-kube-prometheus-prometheus-0 consumes 0.11, which is over its limit.
![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-44-53.jpg?raw=true)

1,85GB of memory buffers, less than 1 GB of free memory, and 0.9GB of cached memory.

![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-46-43.jpg?raw=true)

How many Pods and containers: 32 pods, 58 running containers. 

![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_17-47-50.jpg?raw=true)

Talking about network usage, kube-scheduler-minikube consumes the most and coredns consumes the least.

![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_18-01-15.jpg?raw=true)

During 30 minutes, 13 alerts were received.

![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_18-06-10.jpg?raw=true)

For initContainers, I simply followed the tutorial and used the site from the example.

![alt text](https://github.com/urbeingwatched8/devops/blob/0011527eabfb86960ed5e9bd7ee146d08aedeb76/k8s/screens13-14/photo_2021-10-06_20-32-57.jpg?raw=true)